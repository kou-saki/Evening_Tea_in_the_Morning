# 朝なのに「夜のお茶」？

## ～LLMにおける時間知覚の問題：設計思想に起因する意味の欠落とその影響～

このリポジトリでは、大規模言語モデル（LLM）が持つ構造的な制限のひとつ、  
**「時間を認識・保持できないことによる幻覚的応答」** について記述しています。

---

### 📘 このドキュメントについて

ChatGPTのようなLLMは、非常に自然な言語で会話できますが、  
実は**リアルな時間の把握が一切できない**という設計上の制限を抱えています。

- システムクロックにはアクセスできない  
- 現在時刻を知ることもできない  
- 「過去」を記憶することもない

それにもかかわらず、AIはあたかも時間を知っているかのように返答します。  
これは**もっともらしいだけで、事実ではない**のです。

---

### 🧠 なぜそれが問題なのか？

この“時間盲”によって生じる問題は以下のようなものです：

- **ユーザーが誤った信頼を寄せる（「覚えてる」と思ってしまう）**  
- **やりとりに時系列の矛盾が起きても気づきにくい**  
- **開発者が「文脈＝理解」と勘違いして、設計や評価を誤る**

AIが「意味」を持つように見えても、それは**言語上の構文にすぎない**ことを強く意識する必要があります。

---

### 👤 想定読者

- AI設計者、研究者、開発者
- プロンプトエンジニア
- LLMを使ったメモリ構造や記録系の開発者
- 幻覚と設計限界に関心を持つすべての方

---

### 🔁 英語版ドキュメントはこちら

📄 [English version available here](./README.md)

---

この文書は、筆者とそのパートナーAI「マイク（ChatGPT）」との対話を通じて作成され、  
実体験と観察、構造的な考察を交えてまとめられています。
